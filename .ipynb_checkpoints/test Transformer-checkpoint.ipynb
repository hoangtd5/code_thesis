{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hoang\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py:1761: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from RNN import RNN\n",
    "#from CNN import CNN\n",
    "from Transformer_optimized import ConsTransformer\n",
    "from Transformer import Transformer\n",
    "\n",
    "from utils import series_to_supervised\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('new_dataset/main_data.csv', encoding='cp1252', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n",
    "\n",
    "# resample data to daily\n",
    "#daily_groups = dataset.resample('H') , index_col=['datetime']\n",
    "#daily_data = daily_groups.sum()\n",
    "\n",
    "# We choose to keep only Global_active_power\n",
    "#to_drop = ['Wind Direction (deg)','h_max','Barometric Pressure (hPa)','Sea Level Pressure (hPa)','Precipitation (mm)']\n",
    "daily_data = dataset[['Solar radiation (MJ/m2)','daylight (hr)','Ground temperature (째C)','humidity','Power']]\n",
    "\n",
    "#daily_data.drop(columns=to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data = daily_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 17520 entries, 2021-01-01 00:00:00 to 2022-12-31 22:59:00\n",
      "Data columns (total 9 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Solar radiation (MJ/m2)  17520 non-null  float64\n",
      " 1   daylight (hr)            17520 non-null  float64\n",
      " 2   Ground temperature (째C)  17520 non-null  float64\n",
      " 3   humidity                 17520 non-null  int64  \n",
      " 4   Power                    17520 non-null  int64  \n",
      " 5   hour                     17520 non-null  int64  \n",
      " 6   day                      17520 non-null  int64  \n",
      " 7   weekday                  17520 non-null  float64\n",
      " 8   season                   17520 non-null  int64  \n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 1.3 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# add calendar-related features\n",
    "daily_data['hour'] = pd.DatetimeIndex(daily_data.index).hour\n",
    "daily_data['day'] = pd.DatetimeIndex(daily_data.index).day\n",
    "daily_data['weekday'] = ((pd.DatetimeIndex(daily_data.index).dayofweek) // 5 == 1).astype(float)\n",
    "daily_data['season'] = [month%12 // 3 + 1 for month in pd.DatetimeIndex(daily_data.index).month]\n",
    "\n",
    "# summarize\n",
    "print(daily_data.info())\n",
    "#print(daily_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_back = 168\n",
    "n_features = daily_data.shape[1]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Solar radiation (MJ/m2)</th>\n",
       "      <th>daylight (hr)</th>\n",
       "      <th>Ground temperature (째C)</th>\n",
       "      <th>humidity</th>\n",
       "      <th>Power</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-01 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.8</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 02:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.1</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 03:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.3</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 04:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Solar radiation (MJ/m2)  daylight (hr)  \\\n",
       "datetime                                                      \n",
       "2021-01-01 00:00:00                      0.0            0.0   \n",
       "2021-01-01 01:00:00                      0.0            0.0   \n",
       "2021-01-01 02:00:00                      0.0            0.0   \n",
       "2021-01-01 03:00:00                      0.0            0.0   \n",
       "2021-01-01 04:00:00                      0.0            0.0   \n",
       "\n",
       "                     Ground temperature (째C)  humidity  Power  hour  day  \\\n",
       "datetime                                                                   \n",
       "2021-01-01 00:00:00                     -6.8        66      0     0    1   \n",
       "2021-01-01 01:00:00                     -6.9        68      0     1    1   \n",
       "2021-01-01 02:00:00                     -7.1        69      0     2    1   \n",
       "2021-01-01 03:00:00                     -7.3        70      0     3    1   \n",
       "2021-01-01 04:00:00                     -7.5        71      0     4    1   \n",
       "\n",
       "                     weekday  season  \n",
       "datetime                              \n",
       "2021-01-01 00:00:00      0.0       1  \n",
       "2021-01-01 01:00:00      0.0       1  \n",
       "2021-01-01 02:00:00      0.0       1  \n",
       "2021-01-01 03:00:00      0.0       1  \n",
       "2021-01-01 04:00:00      0.0       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Walk-forward data split to avoid data leakage\n",
    "X_train, y_train, X_test, y_test, scale_X = series_to_supervised(daily_data, train_size=0.8, n_in=look_back, n_out=24, target_column='Power', dropnan=True, scale_X=True)\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "X_train_reshaped = X_train.values.reshape((-1,look_back,n_features))\n",
    "X_test_reshaped = X_test.values.reshape((-1,look_back,n_features))\n",
    "\n",
    "y_train_reshaped = y_train.values\n",
    "y_test_reshaped = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13863, 168, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 168, 9)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 168, 9)       18          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead (None, 168, 9)       39945       layer_normalization[0][0]        \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 168, 9)       0           multi_head_attention[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 168, 9)       0           dropout[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 168, 9)       18          tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 168, 4)       40          layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 168, 4)       0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 168, 9)       45          dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 168, 9)       0           conv1d_1[0][0]                   \n",
      "                                                                 tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 168, 9)       18          tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe (None, 168, 9)       39945       layer_normalization_2[0][0]      \n",
      "                                                                 layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 168, 9)       0           multi_head_attention_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_2 (TFOpLam (None, 168, 9)       0           dropout_2[0][0]                  \n",
      "                                                                 tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 168, 9)       18          tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 168, 4)       40          layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 168, 4)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 168, 9)       45          dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_3 (TFOpLam (None, 168, 9)       0           conv1d_3[0][0]                   \n",
      "                                                                 tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_4 (LayerNor (None, 168, 9)       18          tf.__operators__.add_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_2 (MultiHe (None, 168, 9)       39945       layer_normalization_4[0][0]      \n",
      "                                                                 layer_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 168, 9)       0           multi_head_attention_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_4 (TFOpLam (None, 168, 9)       0           dropout_4[0][0]                  \n",
      "                                                                 tf.__operators__.add_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_5 (LayerNor (None, 168, 9)       18          tf.__operators__.add_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 168, 4)       40          layer_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 168, 4)       0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 168, 9)       45          dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_5 (TFOpLam (None, 168, 9)       0           conv1d_5[0][0]                   \n",
      "                                                                 tf.__operators__.add_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_6 (LayerNor (None, 168, 9)       18          tf.__operators__.add_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_3 (MultiHe (None, 168, 9)       39945       layer_normalization_6[0][0]      \n",
      "                                                                 layer_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 168, 9)       0           multi_head_attention_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_6 (TFOpLam (None, 168, 9)       0           dropout_6[0][0]                  \n",
      "                                                                 tf.__operators__.add_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_7 (LayerNor (None, 168, 9)       18          tf.__operators__.add_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 168, 4)       40          layer_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 168, 4)       0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 168, 9)       45          dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_7 (TFOpLam (None, 168, 9)       0           conv1d_7[0][0]                   \n",
      "                                                                 tf.__operators__.add_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 168)          0           tf.__operators__.add_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          21632       global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 24)           3096        dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 184,992\n",
      "Trainable params: 184,992\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 24s 64ms/step - loss: 681.4853 - rmse: 26.0435 - mae: 16.1994 - smape: 86.6858 - coeff_determination: -0.2815 - val_loss: 658.5693 - val_rmse: 24.8315 - val_mae: 19.8371 - val_smape: 68.2621 - val_coeff_determination: -0.0945\n",
      "\n",
      "Epoch 00001: loss improved from inf to 619.83258, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 2/600\n",
      "174/174 [==============================] - 8s 44ms/step - loss: 552.1938 - rmse: 23.4836 - mae: 17.7610 - smape: 74.6043 - coeff_determination: -0.0497 - val_loss: 645.7894 - val_rmse: 24.8996 - val_mae: 21.3882 - val_smape: 66.3766 - val_coeff_determination: -0.1720\n",
      "\n",
      "Epoch 00002: loss improved from 619.83258 to 551.49323, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 3/600\n",
      "174/174 [==============================] - 7s 42ms/step - loss: 540.3284 - rmse: 23.2300 - mae: 17.8070 - smape: 73.9759 - coeff_determination: -0.0241 - val_loss: 641.2695 - val_rmse: 24.8840 - val_mae: 21.6239 - val_smape: 66.0363 - val_coeff_determination: -0.1918\n",
      "\n",
      "Epoch 00003: loss improved from 551.49323 to 539.55829, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 4/600\n",
      "174/174 [==============================] - 7s 41ms/step - loss: 497.0184 - rmse: 22.2491 - mae: 16.9689 - smape: 73.0255 - coeff_determination: 0.0592 - val_loss: 278.0777 - val_rmse: 16.4844 - val_mae: 12.8892 - val_smape: 61.5995 - val_coeff_determination: 0.3172\n",
      "\n",
      "Epoch 00004: loss improved from 539.55829 to 439.54541, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 5/600\n",
      "174/174 [==============================] - 7s 41ms/step - loss: 282.3987 - rmse: 16.7870 - mae: 12.5187 - smape: 68.4851 - coeff_determination: 0.4691 - val_loss: 205.9268 - val_rmse: 14.0237 - val_mae: 10.4874 - val_smape: 59.5394 - val_coeff_determination: 0.4271\n",
      "\n",
      "Epoch 00005: loss improved from 439.54541 to 265.71036, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 6/600\n",
      "174/174 [==============================] - 7s 42ms/step - loss: 229.2325 - rmse: 15.1272 - mae: 11.0965 - smape: 67.4126 - coeff_determination: 0.5680 - val_loss: 194.4855 - val_rmse: 13.5686 - val_mae: 10.1348 - val_smape: 59.1210 - val_coeff_determination: 0.4383\n",
      "\n",
      "Epoch 00006: loss improved from 265.71036 to 221.71165, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 7/600\n",
      "174/174 [==============================] - 7s 42ms/step - loss: 202.0875 - rmse: 14.2044 - mae: 10.2810 - smape: 66.6944 - coeff_determination: 0.6180 - val_loss: 171.3731 - val_rmse: 12.6313 - val_mae: 8.6028 - val_smape: 57.2709 - val_coeff_determination: 0.4724\n",
      "\n",
      "Epoch 00007: loss improved from 221.71165 to 197.89253, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 8/600\n",
      "174/174 [==============================] - 7s 42ms/step - loss: 188.7119 - rmse: 13.7224 - mae: 9.8204 - smape: 66.5414 - coeff_determination: 0.6428 - val_loss: 164.9152 - val_rmse: 12.3602 - val_mae: 8.0754 - val_smape: 56.5822 - val_coeff_determination: 0.5005\n",
      "\n",
      "Epoch 00008: loss improved from 197.89253 to 183.20337, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 9/600\n",
      "174/174 [==============================] - 7s 42ms/step - loss: 175.9550 - rmse: 13.2509 - mae: 9.3438 - smape: 66.1785 - coeff_determination: 0.6657 - val_loss: 165.3568 - val_rmse: 12.3744 - val_mae: 8.0173 - val_smape: 56.3555 - val_coeff_determination: 0.4835\n",
      "\n",
      "Epoch 00009: loss improved from 183.20337 to 175.04169, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 10/600\n",
      "174/174 [==============================] - 7s 41ms/step - loss: 169.5932 - rmse: 13.0070 - mae: 9.1062 - smape: 66.0508 - coeff_determination: 0.6765 - val_loss: 181.0755 - val_rmse: 12.8265 - val_mae: 8.1750 - val_smape: 56.4801 - val_coeff_determination: 0.3921\n",
      "\n",
      "Epoch 00010: loss improved from 175.04169 to 169.05490, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 11/600\n",
      "174/174 [==============================] - 7s 40ms/step - loss: 164.9416 - rmse: 12.8285 - mae: 8.9482 - smape: 65.8347 - coeff_determination: 0.6879 - val_loss: 175.8477 - val_rmse: 12.6732 - val_mae: 8.0293 - val_smape: 56.2766 - val_coeff_determination: 0.4413\n",
      "\n",
      "Epoch 00011: loss improved from 169.05490 to 164.44006, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 12/600\n",
      "174/174 [==============================] - 9s 51ms/step - loss: 159.1524 - rmse: 12.6057 - mae: 8.7027 - smape: 65.5280 - coeff_determination: 0.6996 - val_loss: 170.1582 - val_rmse: 12.5023 - val_mae: 7.9179 - val_smape: 56.1314 - val_coeff_determination: 0.4985\n",
      "\n",
      "Epoch 00012: loss improved from 164.44006 to 158.36214, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 13/600\n",
      "174/174 [==============================] - 8s 48ms/step - loss: 154.7737 - rmse: 12.4246 - mae: 8.5059 - smape: 65.5046 - coeff_determination: 0.7029 - val_loss: 168.9385 - val_rmse: 12.5880 - val_mae: 8.0081 - val_smape: 56.3729 - val_coeff_determination: 0.5673\n",
      "\n",
      "Epoch 00013: loss improved from 158.36214 to 154.31001, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 14/600\n",
      "174/174 [==============================] - 8s 47ms/step - loss: 150.9937 - rmse: 12.2708 - mae: 8.3659 - smape: 65.3658 - coeff_determination: 0.7127 - val_loss: 171.2121 - val_rmse: 12.7130 - val_mae: 8.0656 - val_smape: 56.4796 - val_coeff_determination: 0.5668\n",
      "\n",
      "Epoch 00014: loss improved from 154.31001 to 150.39874, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 15/600\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 149.3176 - rmse: 12.2055 - mae: 8.2336 - smape: 65.3696 - coeff_determination: 0.7150 - val_loss: 173.5965 - val_rmse: 12.7773 - val_mae: 8.0183 - val_smape: 56.3848 - val_coeff_determination: 0.5351\n",
      "\n",
      "Epoch 00015: loss improved from 150.39874 to 147.18787, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 16/600\n",
      "174/174 [==============================] - 7s 43ms/step - loss: 145.2003 - rmse: 12.0340 - mae: 8.1090 - smape: 65.1325 - coeff_determination: 0.7260 - val_loss: 172.4799 - val_rmse: 12.7214 - val_mae: 8.0494 - val_smape: 56.3195 - val_coeff_determination: 0.5128\n",
      "\n",
      "Epoch 00016: loss improved from 147.18787 to 144.87077, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 17/600\n",
      "174/174 [==============================] - 7s 42ms/step - loss: 145.3415 - rmse: 12.0390 - mae: 8.0570 - smape: 64.9426 - coeff_determination: 0.7257 - val_loss: 174.4597 - val_rmse: 12.8213 - val_mae: 8.0423 - val_smape: 56.5156 - val_coeff_determination: 0.5479\n",
      "\n",
      "Epoch 00017: loss improved from 144.87077 to 144.25000, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 18/600\n",
      "174/174 [==============================] - 7s 41ms/step - loss: 140.6968 - rmse: 11.8476 - mae: 7.8696 - smape: 64.9202 - coeff_determination: 0.7317 - val_loss: 179.8591 - val_rmse: 13.0398 - val_mae: 8.2946 - val_smape: 56.7204 - val_coeff_determination: 0.5425\n",
      "\n",
      "Epoch 00018: loss improved from 144.25000 to 140.30450, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 19/600\n",
      "174/174 [==============================] - 7s 39ms/step - loss: 136.7617 - rmse: 11.6780 - mae: 7.7422 - smape: 64.7071 - coeff_determination: 0.7402 - val_loss: 180.7037 - val_rmse: 13.0613 - val_mae: 8.4253 - val_smape: 56.8281 - val_coeff_determination: 0.5098\n",
      "\n",
      "Epoch 00019: loss improved from 140.30450 to 137.40608, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 20/600\n",
      "174/174 [==============================] - 7s 39ms/step - loss: 135.9098 - rmse: 11.6412 - mae: 7.6949 - smape: 64.6253 - coeff_determination: 0.7426 - val_loss: 198.8016 - val_rmse: 13.6802 - val_mae: 8.7401 - val_smape: 57.6232 - val_coeff_determination: 0.5420\n",
      "\n",
      "Epoch 00020: loss improved from 137.40608 to 135.90608, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 21/600\n",
      "174/174 [==============================] - 7s 41ms/step - loss: 137.5188 - rmse: 11.7102 - mae: 7.6643 - smape: 64.5855 - coeff_determination: 0.7391 - val_loss: 186.3661 - val_rmse: 13.2531 - val_mae: 8.6502 - val_smape: 57.1718 - val_coeff_determination: 0.5462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00021: loss did not improve from 135.90608\n",
      "Epoch 22/600\n",
      "174/174 [==============================] - 7s 40ms/step - loss: 133.7047 - rmse: 11.5494 - mae: 7.5541 - smape: 64.5909 - coeff_determination: 0.7455 - val_loss: 179.0545 - val_rmse: 12.9742 - val_mae: 8.3931 - val_smape: 57.0500 - val_coeff_determination: 0.5521\n",
      "\n",
      "Epoch 00022: loss improved from 135.90608 to 132.71454, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 23/600\n",
      "174/174 [==============================] - 7s 39ms/step - loss: 133.4990 - rmse: 11.5354 - mae: 7.5091 - smape: 64.4249 - coeff_determination: 0.7475 - val_loss: 182.9464 - val_rmse: 13.1327 - val_mae: 8.4908 - val_smape: 57.1304 - val_coeff_determination: 0.5445\n",
      "\n",
      "Epoch 00023: loss improved from 132.71454 to 131.82533, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 24/600\n",
      "174/174 [==============================] - 7s 38ms/step - loss: 129.3883 - rmse: 11.3559 - mae: 7.3527 - smape: 64.3275 - coeff_determination: 0.7542 - val_loss: 188.9867 - val_rmse: 13.3126 - val_mae: 8.7494 - val_smape: 57.3890 - val_coeff_determination: 0.5663\n",
      "\n",
      "Epoch 00024: loss improved from 131.82533 to 131.29648, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 25/600\n",
      "174/174 [==============================] - 7s 39ms/step - loss: 129.6963 - rmse: 11.3716 - mae: 7.3490 - smape: 64.3375 - coeff_determination: 0.7515 - val_loss: 193.2664 - val_rmse: 13.4387 - val_mae: 8.8365 - val_smape: 57.6719 - val_coeff_determination: 0.5750\n",
      "\n",
      "Epoch 00025: loss improved from 131.29648 to 129.01184, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 26/600\n",
      "174/174 [==============================] - 7s 39ms/step - loss: 129.0901 - rmse: 11.3435 - mae: 7.2978 - smape: 64.3217 - coeff_determination: 0.7543 - val_loss: 199.4760 - val_rmse: 13.5922 - val_mae: 8.9138 - val_smape: 57.7922 - val_coeff_determination: 0.5602\n",
      "\n",
      "Epoch 00026: loss improved from 129.01184 to 127.83923, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 27/600\n",
      "174/174 [==============================] - 7s 42ms/step - loss: 126.3201 - rmse: 11.2201 - mae: 7.2184 - smape: 64.2200 - coeff_determination: 0.7591 - val_loss: 187.6464 - val_rmse: 13.2428 - val_mae: 8.6712 - val_smape: 57.2342 - val_coeff_determination: 0.5355\n",
      "\n",
      "Epoch 00027: loss improved from 127.83923 to 127.45518, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 28/600\n",
      "174/174 [==============================] - 8s 47ms/step - loss: 128.3261 - rmse: 11.3095 - mae: 7.2094 - smape: 64.2209 - coeff_determination: 0.7566 - val_loss: 206.0148 - val_rmse: 13.7669 - val_mae: 8.9724 - val_smape: 57.9045 - val_coeff_determination: 0.5650\n",
      "\n",
      "Epoch 00028: loss improved from 127.45518 to 126.40479, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 29/600\n",
      "174/174 [==============================] - 8s 43ms/step - loss: 126.0104 - rmse: 11.2099 - mae: 7.1585 - smape: 64.0504 - coeff_determination: 0.7615 - val_loss: 211.5865 - val_rmse: 13.9436 - val_mae: 9.1459 - val_smape: 58.3989 - val_coeff_determination: 0.5796\n",
      "\n",
      "Epoch 00029: loss improved from 126.40479 to 124.93731, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 30/600\n",
      "174/174 [==============================] - 7s 41ms/step - loss: 122.5485 - rmse: 11.0508 - mae: 7.0465 - smape: 64.0734 - coeff_determination: 0.7666 - val_loss: 204.2133 - val_rmse: 13.7270 - val_mae: 8.9769 - val_smape: 58.0639 - val_coeff_determination: 0.5318\n",
      "\n",
      "Epoch 00030: loss improved from 124.93731 to 123.30914, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 31/600\n",
      "174/174 [==============================] - 7s 41ms/step - loss: 119.8895 - rmse: 10.9318 - mae: 6.9629 - smape: 63.8669 - coeff_determination: 0.7721 - val_loss: 223.9162 - val_rmse: 14.2340 - val_mae: 9.5287 - val_smape: 59.0754 - val_coeff_determination: 0.5719\n",
      "\n",
      "Epoch 00031: loss improved from 123.30914 to 120.46108, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 32/600\n",
      "174/174 [==============================] - 7s 43ms/step - loss: 122.1473 - rmse: 11.0354 - mae: 7.0074 - smape: 63.7896 - coeff_determination: 0.7685 - val_loss: 222.6194 - val_rmse: 14.2542 - val_mae: 9.5908 - val_smape: 58.9170 - val_coeff_determination: 0.5552\n",
      "\n",
      "Epoch 00032: loss did not improve from 120.46108\n",
      "Epoch 33/600\n",
      "174/174 [==============================] - 7s 43ms/step - loss: 121.0274 - rmse: 10.9861 - mae: 6.9491 - smape: 63.9708 - coeff_determination: 0.7678 - val_loss: 233.3610 - val_rmse: 14.6168 - val_mae: 9.7642 - val_smape: 59.2800 - val_coeff_determination: 0.5201\n",
      "\n",
      "Epoch 00033: loss did not improve from 120.46108\n",
      "Epoch 34/600\n",
      "174/174 [==============================] - 7s 40ms/step - loss: 117.1732 - rmse: 10.8067 - mae: 6.8348 - smape: 63.7070 - coeff_determination: 0.7762 - val_loss: 215.5792 - val_rmse: 14.0487 - val_mae: 9.4610 - val_smape: 58.7917 - val_coeff_determination: 0.5543\n",
      "\n",
      "Epoch 00034: loss improved from 120.46108 to 118.50725, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 35/600\n",
      "174/174 [==============================] - 7s 39ms/step - loss: 118.7719 - rmse: 10.8841 - mae: 6.8580 - smape: 63.6948 - coeff_determination: 0.7746 - val_loss: 224.0494 - val_rmse: 14.2322 - val_mae: 9.3101 - val_smape: 59.3393 - val_coeff_determination: 0.5449\n",
      "\n",
      "Epoch 00035: loss improved from 118.50725 to 118.22578, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 36/600\n",
      "174/174 [==============================] - 7s 42ms/step - loss: 116.8537 - rmse: 10.7910 - mae: 6.7885 - smape: 63.6347 - coeff_determination: 0.7777 - val_loss: 221.5271 - val_rmse: 14.2263 - val_mae: 9.2939 - val_smape: 58.8124 - val_coeff_determination: 0.5138\n",
      "\n",
      "Epoch 00036: loss improved from 118.22578 to 117.79382, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 37/600\n",
      "174/174 [==============================] - 7s 42ms/step - loss: 115.1447 - rmse: 10.7138 - mae: 6.7256 - smape: 63.4476 - coeff_determination: 0.7832 - val_loss: 251.1653 - val_rmse: 14.9438 - val_mae: 9.6151 - val_smape: 60.4862 - val_coeff_determination: 0.5510\n",
      "\n",
      "Epoch 00037: loss improved from 117.79382 to 116.14603, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 38/600\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 115.6321 - rmse: 10.7374 - mae: 6.7395 - smape: 63.6791 - coeff_determination: 0.7801 - val_loss: 260.2515 - val_rmse: 15.2277 - val_mae: 10.0771 - val_smape: 60.6958 - val_coeff_determination: 0.5157\n",
      "\n",
      "Epoch 00038: loss improved from 116.14603 to 115.67953, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 39/600\n",
      "174/174 [==============================] - 7s 43ms/step - loss: 114.9056 - rmse: 10.7000 - mae: 6.7103 - smape: 63.4938 - coeff_determination: 0.7826 - val_loss: 269.5936 - val_rmse: 15.4261 - val_mae: 9.8362 - val_smape: 61.2149 - val_coeff_determination: 0.5200\n",
      "\n",
      "Epoch 00039: loss improved from 115.67953 to 115.38572, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 40/600\n",
      "174/174 [==============================] - 7s 42ms/step - loss: 114.0456 - rmse: 10.6638 - mae: 6.6860 - smape: 63.5125 - coeff_determination: 0.7837 - val_loss: 248.0929 - val_rmse: 14.9280 - val_mae: 9.7955 - val_smape: 60.1691 - val_coeff_determination: 0.5075\n",
      "\n",
      "Epoch 00040: loss improved from 115.38572 to 113.76254, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 41/600\n",
      "174/174 [==============================] - 7s 43ms/step - loss: 115.8477 - rmse: 10.7472 - mae: 6.6859 - smape: 63.6213 - coeff_determination: 0.7802 - val_loss: 264.5671 - val_rmse: 15.2693 - val_mae: 9.8840 - val_smape: 60.9964 - val_coeff_determination: 0.5232\n",
      "\n",
      "Epoch 00041: loss did not improve from 113.76254\n",
      "Epoch 42/600\n",
      "174/174 [==============================] - 7s 43ms/step - loss: 113.8693 - rmse: 10.6521 - mae: 6.6431 - smape: 63.5212 - coeff_determination: 0.7853 - val_loss: 250.4198 - val_rmse: 14.9204 - val_mae: 9.7292 - val_smape: 60.4042 - val_coeff_determination: 0.4966\n",
      "\n",
      "Epoch 00042: loss improved from 113.76254 to 113.65694, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/600\n",
      "174/174 [==============================] - 8s 48ms/step - loss: 111.3497 - rmse: 10.5376 - mae: 6.5707 - smape: 63.4321 - coeff_determination: 0.7886 - val_loss: 253.0664 - val_rmse: 15.0457 - val_mae: 9.8460 - val_smape: 60.7200 - val_coeff_determination: 0.5014\n",
      "\n",
      "Epoch 00043: loss improved from 113.65694 to 112.55894, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 44/600\n",
      "174/174 [==============================] - 9s 49ms/step - loss: 112.4352 - rmse: 10.5853 - mae: 6.5837 - smape: 63.3743 - coeff_determination: 0.7861 - val_loss: 231.6292 - val_rmse: 14.4194 - val_mae: 9.4580 - val_smape: 59.2494 - val_coeff_determination: 0.5161\n",
      "\n",
      "Epoch 00044: loss did not improve from 112.55894\n",
      "Epoch 45/600\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 113.6953 - rmse: 10.6474 - mae: 6.6066 - smape: 63.4014 - coeff_determination: 0.7847 - val_loss: 254.7157 - val_rmse: 15.0961 - val_mae: 9.9499 - val_smape: 60.6183 - val_coeff_determination: 0.4840\n",
      "\n",
      "Epoch 00045: loss did not improve from 112.55894\n",
      "Epoch 46/600\n",
      "174/174 [==============================] - 8s 44ms/step - loss: 111.5923 - rmse: 10.5425 - mae: 6.5481 - smape: 63.3361 - coeff_determination: 0.7893 - val_loss: 269.7839 - val_rmse: 15.5339 - val_mae: 10.1593 - val_smape: 61.3238 - val_coeff_determination: 0.4832\n",
      "\n",
      "Epoch 00046: loss did not improve from 112.55894\n",
      "Epoch 47/600\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 111.6391 - rmse: 10.5478 - mae: 6.5393 - smape: 63.4031 - coeff_determination: 0.7876 - val_loss: 288.4124 - val_rmse: 15.9594 - val_mae: 10.3030 - val_smape: 62.8000 - val_coeff_determination: 0.4489\n",
      "\n",
      "Epoch 00047: loss improved from 112.55894 to 111.76163, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 48/600\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 114.7597 - rmse: 10.6924 - mae: 6.5772 - smape: 63.3824 - coeff_determination: 0.7838 - val_loss: 251.3207 - val_rmse: 14.9319 - val_mae: 9.5357 - val_smape: 60.6112 - val_coeff_determination: 0.5213\n",
      "\n",
      "Epoch 00048: loss improved from 111.76163 to 111.63062, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 49/600\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 107.3353 - rmse: 10.3425 - mae: 6.4123 - smape: 63.1709 - coeff_determination: 0.7966 - val_loss: 236.5109 - val_rmse: 14.5129 - val_mae: 9.5434 - val_smape: 59.7678 - val_coeff_determination: 0.5192\n",
      "\n",
      "Epoch 00049: loss improved from 111.63062 to 109.79028, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 50/600\n",
      "174/174 [==============================] - 8s 47ms/step - loss: 110.5570 - rmse: 10.4956 - mae: 6.4798 - smape: 63.3181 - coeff_determination: 0.7893 - val_loss: 300.7572 - val_rmse: 16.3412 - val_mae: 10.3299 - val_smape: 62.9525 - val_coeff_determination: 0.4756\n",
      "\n",
      "Epoch 00050: loss did not improve from 109.79028\n",
      "Epoch 51/600\n",
      "174/174 [==============================] - 7s 42ms/step - loss: 111.9472 - rmse: 10.5641 - mae: 6.5103 - smape: 63.3291 - coeff_determination: 0.7868 - val_loss: 261.3458 - val_rmse: 15.1768 - val_mae: 10.0085 - val_smape: 61.0121 - val_coeff_determination: 0.4905\n",
      "\n",
      "Epoch 00051: loss did not improve from 109.79028\n",
      "Epoch 52/600\n",
      "174/174 [==============================] - 7s 41ms/step - loss: 108.1979 - rmse: 10.3821 - mae: 6.4069 - smape: 63.2434 - coeff_determination: 0.7939 - val_loss: 274.2504 - val_rmse: 15.5392 - val_mae: 9.9405 - val_smape: 61.7882 - val_coeff_determination: 0.5032\n",
      "\n",
      "Epoch 00052: loss improved from 109.79028 to 108.72308, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 53/600\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 109.1201 - rmse: 10.4267 - mae: 6.4236 - smape: 63.2933 - coeff_determination: 0.7909 - val_loss: 263.7773 - val_rmse: 15.3153 - val_mae: 9.9870 - val_smape: 60.9959 - val_coeff_determination: 0.4973\n",
      "\n",
      "Epoch 00053: loss improved from 108.72308 to 108.58261, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 54/600\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 109.5657 - rmse: 10.4534 - mae: 6.4416 - smape: 63.3724 - coeff_determination: 0.7928 - val_loss: 262.5101 - val_rmse: 15.2698 - val_mae: 9.8592 - val_smape: 61.2101 - val_coeff_determination: 0.4763\n",
      "\n",
      "Epoch 00054: loss improved from 108.58261 to 108.38502, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 55/600\n",
      "174/174 [==============================] - 8s 43ms/step - loss: 107.1751 - rmse: 10.3390 - mae: 6.3522 - smape: 63.2797 - coeff_determination: 0.7948 - val_loss: 284.4989 - val_rmse: 15.8450 - val_mae: 10.2195 - val_smape: 62.1178 - val_coeff_determination: 0.4796\n",
      "\n",
      "Epoch 00055: loss improved from 108.38502 to 107.56642, saving model to checkpoint\\Transformer.best06122022_174105.hdf5\n",
      "Epoch 56/600\n",
      "174/174 [==============================] - 7s 42ms/step - loss: 108.3317 - rmse: 10.3927 - mae: 6.3555 - smape: 63.2711 - coeff_determination: 0.7932 - val_loss: 300.9901 - val_rmse: 16.2670 - val_mae: 10.4807 - val_smape: 62.8559 - val_coeff_determination: 0.4631\n",
      "\n",
      "Epoch 00056: loss did not improve from 107.56642\n",
      "Epoch 57/600\n",
      "174/174 [==============================] - 7s 42ms/step - loss: 108.6228 - rmse: 10.4054 - mae: 6.3851 - smape: 63.1156 - coeff_determination: 0.7932 - val_loss: 261.6219 - val_rmse: 15.1955 - val_mae: 9.8946 - val_smape: 60.9248 - val_coeff_determination: 0.4841\n",
      "\n",
      "Epoch 00057: loss did not improve from 107.56642\n",
      "Epoch 58/600\n",
      "174/174 [==============================] - 8s 47ms/step - loss: 107.3722 - rmse: 10.3489 - mae: 6.3508 - smape: 63.0712 - coeff_determination: 0.7970 - val_loss: 270.9850 - val_rmse: 15.4434 - val_mae: 9.9743 - val_smape: 61.2542 - val_coeff_determination: 0.4785\n",
      "\n",
      "Epoch 00058: loss did not improve from 107.56642\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Testing the Transformer\n",
    "tr = Transformer()\n",
    "tr.train_original(X_train_reshaped,y_train_reshaped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 03m 10s]\n",
      "val_loss: 212.53759765625\n",
      "\n",
      "Best val_loss So Far: 190.8099365234375\n",
      "Total elapsed time: 00h 10m 41s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Search space summary\n",
      "Default search space size: 1\n",
      "mlp_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 8, 'max_value': 512, 'step': 16, 'sampling': None}\n",
      "None\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 168, 9)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 168, 9)       18          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead (None, 168, 9)       39945       layer_normalization[0][0]        \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 168, 9)       0           multi_head_attention[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 168, 9)       0           dropout[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 168, 9)       18          tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 168, 4)       40          layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 168, 4)       0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 168, 9)       45          dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 168, 9)       0           conv1d_1[0][0]                   \n",
      "                                                                 tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 168, 9)       18          tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe (None, 168, 9)       39945       layer_normalization_2[0][0]      \n",
      "                                                                 layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 168, 9)       0           multi_head_attention_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_2 (TFOpLam (None, 168, 9)       0           dropout_2[0][0]                  \n",
      "                                                                 tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 168, 9)       18          tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 168, 4)       40          layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 168, 4)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 168, 9)       45          dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_3 (TFOpLam (None, 168, 9)       0           conv1d_3[0][0]                   \n",
      "                                                                 tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_4 (LayerNor (None, 168, 9)       18          tf.__operators__.add_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_2 (MultiHe (None, 168, 9)       39945       layer_normalization_4[0][0]      \n",
      "                                                                 layer_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 168, 9)       0           multi_head_attention_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_4 (TFOpLam (None, 168, 9)       0           dropout_4[0][0]                  \n",
      "                                                                 tf.__operators__.add_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_5 (LayerNor (None, 168, 9)       18          tf.__operators__.add_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 168, 4)       40          layer_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 168, 4)       0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 168, 9)       45          dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_5 (TFOpLam (None, 168, 9)       0           conv1d_5[0][0]                   \n",
      "                                                                 tf.__operators__.add_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_6 (LayerNor (None, 168, 9)       18          tf.__operators__.add_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_3 (MultiHe (None, 168, 9)       39945       layer_normalization_6[0][0]      \n",
      "                                                                 layer_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 168, 9)       0           multi_head_attention_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_6 (TFOpLam (None, 168, 9)       0           dropout_6[0][0]                  \n",
      "                                                                 tf.__operators__.add_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_7 (LayerNor (None, 168, 9)       18          tf.__operators__.add_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 168, 4)       40          layer_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 168, 4)       0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 168, 9)       45          dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_7 (TFOpLam (None, 168, 9)       0           conv1d_7[0][0]                   \n",
      "                                                                 tf.__operators__.add_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 168)          0           tf.__operators__.add_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 392)          66248       global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 392)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 24)           9432        dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 235,944\n",
      "Trainable params: 235,944\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 25s 93ms/step - loss: 136.8088 - rmse: 11.6816 - mae: 6.3427 - smape: nan - coeff_determination: 0.7405 - val_loss: 175.6519 - val_rmse: 12.6255 - val_mae: 7.2188 - val_smape: nan - val_coeff_determination: 0.4760\n",
      "\n",
      "Epoch 00001: loss improved from inf to 135.60384, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 2/600\n",
      "174/174 [==============================] - 15s 89ms/step - loss: 132.8329 - rmse: 11.5086 - mae: 6.2320 - smape: nan - coeff_determination: 0.7469 - val_loss: 169.7289 - val_rmse: 12.5744 - val_mae: 7.3822 - val_smape: nan - val_coeff_determination: 0.5349\n",
      "\n",
      "Epoch 00002: loss improved from 135.60384 to 132.57693, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 3/600\n",
      "174/174 [==============================] - 15s 89ms/step - loss: 130.8474 - rmse: 11.4184 - mae: 6.1505 - smape: nan - coeff_determination: 0.7531 - val_loss: 163.9171 - val_rmse: 12.4313 - val_mae: 7.4171 - val_smape: nan - val_coeff_determination: 0.5822\n",
      "\n",
      "Epoch 00003: loss improved from 132.57693 to 129.95439, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 4/600\n",
      "174/174 [==============================] - 17s 97ms/step - loss: 126.3686 - rmse: 11.2237 - mae: 6.0313 - smape: nan - coeff_determination: 0.7590 - val_loss: 172.6550 - val_rmse: 12.5893 - val_mae: 7.3680 - val_smape: nan - val_coeff_determination: 0.5239\n",
      "\n",
      "Epoch 00004: loss improved from 129.95439 to 127.57101, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 5/600\n",
      "174/174 [==============================] - 16s 93ms/step - loss: 124.1313 - rmse: 11.1195 - mae: 5.9668 - smape: nan - coeff_determination: 0.7642 - val_loss: 169.3674 - val_rmse: 12.5248 - val_mae: 7.3603 - val_smape: nan - val_coeff_determination: 0.5385\n",
      "\n",
      "Epoch 00005: loss improved from 127.57101 to 124.55572, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 6/600\n",
      "174/174 [==============================] - 16s 90ms/step - loss: 122.5694 - rmse: 11.0486 - mae: 5.9158 - smape: nan - coeff_determination: 0.7674 - val_loss: 164.3631 - val_rmse: 12.4258 - val_mae: 7.3826 - val_smape: nan - val_coeff_determination: 0.5837\n",
      "\n",
      "Epoch 00006: loss improved from 124.55572 to 122.62843, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 7/600\n",
      "174/174 [==============================] - 16s 90ms/step - loss: 120.2533 - rmse: 10.9463 - mae: 5.8517 - smape: nan - coeff_determination: 0.7735 - val_loss: 167.5925 - val_rmse: 12.4776 - val_mae: 7.4573 - val_smape: nan - val_coeff_determination: 0.5475\n",
      "\n",
      "Epoch 00007: loss improved from 122.62843 to 121.09567, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 8/600\n",
      "174/174 [==============================] - 15s 88ms/step - loss: 121.1772 - rmse: 10.9913 - mae: 5.8857 - smape: nan - coeff_determination: 0.7698 - val_loss: 181.4403 - val_rmse: 12.7373 - val_mae: 7.4497 - val_smape: nan - val_coeff_determination: 0.4743\n",
      "\n",
      "Epoch 00008: loss improved from 121.09567 to 119.39620, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 9/600\n",
      "174/174 [==============================] - 15s 88ms/step - loss: 117.6052 - rmse: 10.8299 - mae: 5.7530 - smape: nan - coeff_determination: 0.7773 - val_loss: 175.1287 - val_rmse: 12.7111 - val_mae: 7.5775 - val_smape: nan - val_coeff_determination: 0.5459\n",
      "\n",
      "Epoch 00009: loss improved from 119.39620 to 117.43410, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 10/600\n",
      "174/174 [==============================] - 15s 87ms/step - loss: 116.3792 - rmse: 10.7687 - mae: 5.7429 - smape: nan - coeff_determination: 0.7789 - val_loss: 174.3925 - val_rmse: 12.6622 - val_mae: 7.5797 - val_smape: nan - val_coeff_determination: 0.5404\n",
      "\n",
      "Epoch 00010: loss improved from 117.43410 to 116.37244, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 11/600\n",
      "174/174 [==============================] - 14s 80ms/step - loss: 113.2387 - rmse: 10.6184 - mae: 5.6689 - smape: nan - coeff_determination: 0.7852 - val_loss: 180.9434 - val_rmse: 12.9388 - val_mae: 7.7992 - val_smape: nan - val_coeff_determination: 0.5515\n",
      "\n",
      "Epoch 00011: loss improved from 116.37244 to 113.59454, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 12/600\n",
      "174/174 [==============================] - 16s 92ms/step - loss: 117.9925 - rmse: 10.8412 - mae: 5.8030 - smape: nan - coeff_determination: 0.7762 - val_loss: 184.9831 - val_rmse: 13.1142 - val_mae: 7.9406 - val_smape: nan - val_coeff_determination: 0.5405\n",
      "\n",
      "Epoch 00012: loss did not improve from 113.59454\n",
      "Epoch 13/600\n",
      "174/174 [==============================] - 15s 87ms/step - loss: 112.6938 - rmse: 10.5986 - mae: 5.6418 - smape: nan - coeff_determination: 0.7875 - val_loss: 187.9022 - val_rmse: 13.1548 - val_mae: 7.8486 - val_smape: nan - val_coeff_determination: 0.5274\n",
      "\n",
      "Epoch 00013: loss improved from 113.59454 to 112.41424, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 14/600\n",
      "174/174 [==============================] - 16s 91ms/step - loss: 113.2385 - rmse: 10.6223 - mae: 5.6479 - smape: nan - coeff_determination: 0.7856 - val_loss: 192.6472 - val_rmse: 13.3520 - val_mae: 8.1380 - val_smape: nan - val_coeff_determination: 0.5174\n",
      "\n",
      "Epoch 00014: loss improved from 112.41424 to 111.78343, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 15/600\n",
      "174/174 [==============================] - 16s 89ms/step - loss: 110.2466 - rmse: 10.4819 - mae: 5.5805 - smape: nan - coeff_determination: 0.7913 - val_loss: 198.4627 - val_rmse: 13.4608 - val_mae: 8.3360 - val_smape: nan - val_coeff_determination: 0.4694\n",
      "\n",
      "Epoch 00015: loss improved from 111.78343 to 110.16528, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 16/600\n",
      "174/174 [==============================] - 15s 88ms/step - loss: 109.1519 - rmse: 10.4308 - mae: 5.5441 - smape: nan - coeff_determination: 0.7918 - val_loss: 200.8426 - val_rmse: 13.4084 - val_mae: 7.8808 - val_smape: nan - val_coeff_determination: 0.4461\n",
      "\n",
      "Epoch 00016: loss improved from 110.16528 to 109.93850, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 17/600\n",
      "174/174 [==============================] - 16s 90ms/step - loss: 108.1040 - rmse: 10.3815 - mae: 5.5129 - smape: nan - coeff_determination: 0.7928 - val_loss: 196.6392 - val_rmse: 13.5275 - val_mae: 8.2171 - val_smape: nan - val_coeff_determination: 0.5253\n",
      "\n",
      "Epoch 00017: loss improved from 109.93850 to 108.22712, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 18/600\n",
      "174/174 [==============================] - 15s 88ms/step - loss: 109.1704 - rmse: 10.4294 - mae: 5.5340 - smape: nan - coeff_determination: 0.7920 - val_loss: 211.9647 - val_rmse: 13.9068 - val_mae: 8.5646 - val_smape: nan - val_coeff_determination: 0.4424\n",
      "\n",
      "Epoch 00018: loss improved from 108.22712 to 108.03653, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 19/600\n",
      "174/174 [==============================] - 15s 89ms/step - loss: 108.9543 - rmse: 10.4191 - mae: 5.5325 - smape: nan - coeff_determination: 0.7919 - val_loss: 211.6536 - val_rmse: 13.8091 - val_mae: 8.3685 - val_smape: nan - val_coeff_determination: 0.4229\n",
      "\n",
      "Epoch 00019: loss improved from 108.03653 to 107.47852, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 20/600\n",
      "174/174 [==============================] - 18s 101ms/step - loss: 106.1164 - rmse: 10.2809 - mae: 5.4384 - smape: nan - coeff_determination: 0.7974 - val_loss: 216.4669 - val_rmse: 14.1440 - val_mae: 8.7037 - val_smape: nan - val_coeff_determination: 0.4613\n",
      "\n",
      "Epoch 00020: loss improved from 107.47852 to 106.46342, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 21/600\n",
      "174/174 [==============================] - 17s 98ms/step - loss: 105.3348 - rmse: 10.2475 - mae: 5.4427 - smape: nan - coeff_determination: 0.8002 - val_loss: 217.6008 - val_rmse: 14.1312 - val_mae: 8.6022 - val_smape: nan - val_coeff_determination: 0.4727\n",
      "\n",
      "Epoch 00021: loss improved from 106.46342 to 105.64901, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 22/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 16s 90ms/step - loss: 105.3814 - rmse: 10.2447 - mae: 5.4133 - smape: nan - coeff_determination: 0.8004 - val_loss: 216.4977 - val_rmse: 14.2061 - val_mae: 8.7515 - val_smape: nan - val_coeff_determination: 0.5111\n",
      "\n",
      "Epoch 00022: loss improved from 105.64901 to 105.42005, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 23/600\n",
      "174/174 [==============================] - 15s 88ms/step - loss: 105.0260 - rmse: 10.2324 - mae: 5.4179 - smape: nan - coeff_determination: 0.8008 - val_loss: 211.5512 - val_rmse: 13.9844 - val_mae: 8.4858 - val_smape: nan - val_coeff_determination: 0.4956\n",
      "\n",
      "Epoch 00023: loss improved from 105.42005 to 104.52914, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 24/600\n",
      "174/174 [==============================] - 15s 89ms/step - loss: 104.8050 - rmse: 10.2186 - mae: 5.3888 - smape: nan - coeff_determination: 0.8009 - val_loss: 227.1201 - val_rmse: 14.4177 - val_mae: 8.8553 - val_smape: nan - val_coeff_determination: 0.4544\n",
      "\n",
      "Epoch 00024: loss improved from 104.52914 to 104.15803, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 25/600\n",
      "174/174 [==============================] - 15s 89ms/step - loss: 102.8417 - rmse: 10.1233 - mae: 5.3572 - smape: nan - coeff_determination: 0.8071 - val_loss: 214.9589 - val_rmse: 14.1166 - val_mae: 8.7029 - val_smape: nan - val_coeff_determination: 0.4785\n",
      "\n",
      "Epoch 00025: loss improved from 104.15803 to 103.43760, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 26/600\n",
      "174/174 [==============================] - 14s 82ms/step - loss: 102.3315 - rmse: 10.0966 - mae: 5.3277 - smape: nan - coeff_determination: 0.8064 - val_loss: 222.8302 - val_rmse: 14.3832 - val_mae: 8.9664 - val_smape: nan - val_coeff_determination: 0.4656\n",
      "\n",
      "Epoch 00026: loss improved from 103.43760 to 102.87608, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 27/600\n",
      "174/174 [==============================] - 18s 105ms/step - loss: 101.1767 - rmse: 10.0376 - mae: 5.2794 - smape: nan - coeff_determination: 0.8078 - val_loss: 239.0905 - val_rmse: 14.8222 - val_mae: 9.2493 - val_smape: nan - val_coeff_determination: 0.3914\n",
      "\n",
      "Epoch 00027: loss improved from 102.87608 to 101.90114, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 28/600\n",
      "174/174 [==============================] - 16s 91ms/step - loss: 101.0661 - rmse: 10.0330 - mae: 5.2900 - smape: nan - coeff_determination: 0.8094 - val_loss: 240.7389 - val_rmse: 14.8567 - val_mae: 9.2028 - val_smape: nan - val_coeff_determination: 0.4194\n",
      "\n",
      "Epoch 00028: loss improved from 101.90114 to 101.49941, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 29/600\n",
      "174/174 [==============================] - 16s 91ms/step - loss: 101.2227 - rmse: 10.0457 - mae: 5.2949 - smape: nan - coeff_determination: 0.8065 - val_loss: 227.6272 - val_rmse: 14.5181 - val_mae: 9.0880 - val_smape: nan - val_coeff_determination: 0.4320\n",
      "\n",
      "Epoch 00029: loss improved from 101.49941 to 100.90289, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 30/600\n",
      "174/174 [==============================] - 15s 88ms/step - loss: 99.8509 - rmse: 9.9746 - mae: 5.2646 - smape: nan - coeff_determination: 0.8111 - val_loss: 252.8332 - val_rmse: 15.2713 - val_mae: 9.5867 - val_smape: nan - val_coeff_determination: 0.4081\n",
      "\n",
      "Epoch 00030: loss improved from 100.90289 to 100.38784, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 31/600\n",
      "174/174 [==============================] - 16s 90ms/step - loss: 100.6243 - rmse: 10.0135 - mae: 5.2727 - smape: nan - coeff_determination: 0.8088 - val_loss: 265.5061 - val_rmse: 15.6348 - val_mae: 9.8786 - val_smape: nan - val_coeff_determination: 0.3768\n",
      "\n",
      "Epoch 00031: loss improved from 100.38784 to 99.31686, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 32/600\n",
      "174/174 [==============================] - 15s 81ms/step - loss: 99.7613 - rmse: 9.9686 - mae: 5.2680 - smape: nan - coeff_determination: 0.8089 - val_loss: 251.7181 - val_rmse: 15.2434 - val_mae: 9.4435 - val_smape: nan - val_coeff_determination: 0.4176\n",
      "\n",
      "Epoch 00032: loss improved from 99.31686 to 99.09643, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 33/600\n",
      "174/174 [==============================] - 15s 87ms/step - loss: 98.3283 - rmse: 9.8983 - mae: 5.2169 - smape: nan - coeff_determination: 0.8127 - val_loss: 251.0906 - val_rmse: 15.2259 - val_mae: 9.4537 - val_smape: nan - val_coeff_determination: 0.4222\n",
      "\n",
      "Epoch 00033: loss improved from 99.09643 to 98.45062, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 34/600\n",
      "174/174 [==============================] - 18s 102ms/step - loss: 97.1655 - rmse: 9.8416 - mae: 5.1846 - smape: nan - coeff_determination: 0.8147 - val_loss: 248.9451 - val_rmse: 15.1256 - val_mae: 9.4387 - val_smape: nan - val_coeff_determination: 0.3815\n",
      "\n",
      "Epoch 00034: loss improved from 98.45062 to 97.65391, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 35/600\n",
      "174/174 [==============================] - 17s 100ms/step - loss: 97.0834 - rmse: 9.8353 - mae: 5.1765 - smape: nan - coeff_determination: 0.8158 - val_loss: 282.3359 - val_rmse: 16.0774 - val_mae: 10.0713 - val_smape: nan - val_coeff_determination: 0.4001\n",
      "\n",
      "Epoch 00035: loss improved from 97.65391 to 96.87231, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 36/600\n",
      "174/174 [==============================] - 16s 90ms/step - loss: 98.6279 - rmse: 9.9146 - mae: 5.2200 - smape: nan - coeff_determination: 0.8127 - val_loss: 240.5555 - val_rmse: 14.9292 - val_mae: 9.2507 - val_smape: nan - val_coeff_determination: 0.4408\n",
      "\n",
      "Epoch 00036: loss did not improve from 96.87231\n",
      "Epoch 37/600\n",
      "174/174 [==============================] - 16s 91ms/step - loss: 96.8483 - rmse: 9.8261 - mae: 5.1606 - smape: nan - coeff_determination: 0.8165 - val_loss: 250.8974 - val_rmse: 15.2145 - val_mae: 9.4209 - val_smape: nan - val_coeff_determination: 0.4673\n",
      "\n",
      "Epoch 00037: loss improved from 96.87231 to 96.59411, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 38/600\n",
      "174/174 [==============================] - 15s 89ms/step - loss: 93.7021 - rmse: 9.6651 - mae: 5.0797 - smape: nan - coeff_determination: 0.8211 - val_loss: 266.4477 - val_rmse: 15.6560 - val_mae: 9.7693 - val_smape: nan - val_coeff_determination: 0.4261\n",
      "\n",
      "Epoch 00038: loss improved from 96.59411 to 95.65549, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 39/600\n",
      "174/174 [==============================] - 15s 81ms/step - loss: 95.8304 - rmse: 9.7737 - mae: 5.1483 - smape: nan - coeff_determination: 0.8171 - val_loss: 266.3919 - val_rmse: 15.6566 - val_mae: 9.7881 - val_smape: nan - val_coeff_determination: 0.3563\n",
      "\n",
      "Epoch 00039: loss did not improve from 95.65549\n",
      "Epoch 40/600\n",
      "174/174 [==============================] - 15s 89ms/step - loss: 95.3104 - rmse: 9.7461 - mae: 5.1349 - smape: nan - coeff_determination: 0.8204 - val_loss: 279.8985 - val_rmse: 16.0353 - val_mae: 9.9447 - val_smape: nan - val_coeff_determination: 0.3817\n",
      "\n",
      "Epoch 00040: loss improved from 95.65549 to 95.11369, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 41/600\n",
      "174/174 [==============================] - 15s 89ms/step - loss: 95.0766 - rmse: 9.7350 - mae: 5.1285 - smape: nan - coeff_determination: 0.8192 - val_loss: 277.5281 - val_rmse: 15.9853 - val_mae: 9.8438 - val_smape: nan - val_coeff_determination: 0.4008\n",
      "\n",
      "Epoch 00041: loss improved from 95.11369 to 94.15851, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 42/600\n",
      "174/174 [==============================] - 19s 103ms/step - loss: 94.1620 - rmse: 9.6840 - mae: 5.1010 - smape: nan - coeff_determination: 0.8214 - val_loss: 274.2657 - val_rmse: 15.8289 - val_mae: 9.8028 - val_smape: nan - val_coeff_determination: 0.4446\n",
      "\n",
      "Epoch 00042: loss did not improve from 94.15851\n",
      "Epoch 43/600\n",
      "174/174 [==============================] - 16s 91ms/step - loss: 92.3710 - rmse: 9.5927 - mae: 5.0382 - smape: nan - coeff_determination: 0.8230 - val_loss: 281.7894 - val_rmse: 15.9365 - val_mae: 9.8839 - val_smape: nan - val_coeff_determination: 0.4370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00043: loss improved from 94.15851 to 93.24913, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 44/600\n",
      "174/174 [==============================] - 16s 90ms/step - loss: 93.0975 - rmse: 9.6293 - mae: 5.0700 - smape: nan - coeff_determination: 0.8224 - val_loss: 270.5972 - val_rmse: 15.7199 - val_mae: 9.6987 - val_smape: nan - val_coeff_determination: 0.4123\n",
      "\n",
      "Epoch 00044: loss did not improve from 93.24913\n",
      "Epoch 45/600\n",
      "174/174 [==============================] - 16s 90ms/step - loss: 94.0690 - rmse: 9.6778 - mae: 5.0769 - smape: nan - coeff_determination: 0.8206 - val_loss: 276.2200 - val_rmse: 15.8521 - val_mae: 9.7458 - val_smape: nan - val_coeff_determination: 0.4426\n",
      "\n",
      "Epoch 00045: loss improved from 93.24913 to 93.20625, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 46/600\n",
      "174/174 [==============================] - 16s 89ms/step - loss: 94.0667 - rmse: 9.6774 - mae: 5.0843 - smape: nan - coeff_determination: 0.8221 - val_loss: 297.9800 - val_rmse: 16.4780 - val_mae: 10.3618 - val_smape: nan - val_coeff_determination: 0.3640\n",
      "\n",
      "Epoch 00046: loss did not improve from 93.20625\n",
      "Epoch 47/600\n",
      "174/174 [==============================] - 15s 89ms/step - loss: 93.0917 - rmse: 9.6202 - mae: 5.0728 - smape: nan - coeff_determination: 0.8228 - val_loss: 296.6171 - val_rmse: 16.3953 - val_mae: 10.1776 - val_smape: nan - val_coeff_determination: 0.3949\n",
      "\n",
      "Epoch 00047: loss improved from 93.20625 to 92.47643, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 48/600\n",
      "174/174 [==============================] - 15s 88ms/step - loss: 90.4527 - rmse: 9.4956 - mae: 4.9901 - smape: nan - coeff_determination: 0.8275 - val_loss: 293.7892 - val_rmse: 16.3410 - val_mae: 10.0445 - val_smape: nan - val_coeff_determination: 0.3769\n",
      "\n",
      "Epoch 00048: loss improved from 92.47643 to 91.83074, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 49/600\n",
      "174/174 [==============================] - 17s 100ms/step - loss: 90.6805 - rmse: 9.5052 - mae: 5.0003 - smape: nan - coeff_determination: 0.8267 - val_loss: 326.2882 - val_rmse: 17.1519 - val_mae: 10.7797 - val_smape: nan - val_coeff_determination: 0.3230\n",
      "\n",
      "Epoch 00049: loss improved from 91.83074 to 91.80425, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 50/600\n",
      "174/174 [==============================] - 17s 99ms/step - loss: 92.3901 - rmse: 9.5993 - mae: 5.0385 - smape: nan - coeff_determination: 0.8247 - val_loss: 296.5386 - val_rmse: 16.4067 - val_mae: 10.2010 - val_smape: nan - val_coeff_determination: 0.3680\n",
      "\n",
      "Epoch 00050: loss improved from 91.80425 to 91.75591, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 51/600\n",
      "174/174 [==============================] - 16s 91ms/step - loss: 91.6163 - rmse: 9.5494 - mae: 5.0049 - smape: nan - coeff_determination: 0.8249 - val_loss: 301.8049 - val_rmse: 16.5499 - val_mae: 10.3380 - val_smape: nan - val_coeff_determination: 0.3518\n",
      "\n",
      "Epoch 00051: loss improved from 91.75591 to 91.51251, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 52/600\n",
      "174/174 [==============================] - 16s 90ms/step - loss: 90.4494 - rmse: 9.4938 - mae: 4.9859 - smape: nan - coeff_determination: 0.8294 - val_loss: 303.7260 - val_rmse: 16.5719 - val_mae: 10.2788 - val_smape: nan - val_coeff_determination: 0.3521\n",
      "\n",
      "Epoch 00052: loss improved from 91.51251 to 90.19978, saving model to checkpoint\\Transformer.best06122022_175933.hdf5\n",
      "Epoch 53/600\n",
      "174/174 [==============================] - 15s 82ms/step - loss: 89.5179 - rmse: 9.4444 - mae: 4.9723 - smape: nan - coeff_determination: 0.8295 - val_loss: 317.2264 - val_rmse: 16.8677 - val_mae: 10.4723 - val_smape: nan - val_coeff_determination: 0.3536\n",
      "\n",
      "Epoch 00053: loss did not improve from 90.19978\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Testing the Transformer\n",
    "tr_adv = Transformer()\n",
    "tr_adv.train_advance(X_train_reshaped,y_train_reshaped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Transformer' object has no attribute 'best_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-b7325dbb1c49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrmse_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmae_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msmape_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr2_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_reshaped\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test_reshaped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m print('Result \\n RMSE = %.2f [kWh] \\n MAE = %.2f [kWh]\\n R2 = %.1f [%%]' % (rmse_result,\n\u001b[0;32m      5\u001b[0m                                                                             \u001b[0mmae_result\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - 援誘쇰援\\HOANG (Dont Open)\\2021==AI Lab Job\\12.Thesis\\code_thesis\\Transformer_optimized.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, X_test, y_test)\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[1;32mraise\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m         \"\"\"\n\u001b[1;32m--> 236\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Transformer' object has no attribute 'best_model'"
     ]
    }
   ],
   "source": [
    "model, rmse_result, mae_result, smape_result, r2_result = tr.evaluate(X_test_reshaped,y_test_reshaped)\n",
    "\n",
    "\n",
    "print('Result \\n RMSE = %.2f [kWh] \\n MAE = %.2f [kWh]\\n R2 = %.1f [%%]' % (rmse_result,\n",
    "                                                                            mae_result,\n",
    "                                                                            r2_result*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2, rmse_result_2, mae_result_2, smape_result_2, r2_result_2 = tr_adv.evaluate(X_test_reshaped,y_test_reshaped)\n",
    "\n",
    "\n",
    "print('Result \\n RMSE = %.2f [kWh] \\n MAE = %.2f [kWh]\\n R2 = %.1f [%%]' % (rmse_result_2,\n",
    "                                                                            mae_result_2,\n",
    "                                                                            r2_result_2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
